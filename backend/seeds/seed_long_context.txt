[
  "Minimax scaling on [1,α] and failure of the two‑regime rule. Fix α≥1, L∈ℕ, and θ_j>0. For s∈[1,α], define J(s)=\\sup_{|\\Delta|\\le \\alpha L}\\big|\\sin(\\Delta\\,\\theta_j/s)-\\sin(\\Delta\\,\\theta_j/\\alpha)\\big|. Then J(s) is uniquely minimized at s=\\alpha. Consequently, the choice s_j^{\\star}:=\\min\\{\\alpha,\\sqrt{L/\\lambda_j}\\} minimizes J if and only if \\sqrt{L/\\lambda_j}\\ge\\alpha; if 1\\le\\sqrt{L/\\lambda_j}<\\alpha it is strictly suboptimal, and if \\sqrt{L/\\lambda_j}<1 it is infeasible under the constraint s\\in[1,\\alpha].",
  "Residue-balanced finetuning does not guarantee zero expected gradient on resonant coordinates: even if positions m are sampled uniformly over each residue class modulo every $\\hat\\lambda_j(\\alpha)$ in $S_\\alpha$, there exists a positive semidefinite quadratic feature-matching loss to a PI teacher for which the expected gradient on $I_{S_\\alpha}$ is nonzero.",
  "ALiBi‑assisted lobe suppression: corrected result. Let $K_\\infty(\\Delta):=\\dfrac{1}{\\ln\\alpha}\\int_{1/\\alpha}^1 \\dfrac{\\cos(\\Delta u)}{u}\\,du$ with $\\alpha>1$, and for $\\beta\\in\\mathbb R$ set $K_\\infty^{(\\beta)}(\\Delta):=K_\\infty(\\Delta)-\\beta\\,|\\Delta|$. Then for any $L>0$ and $\\Delta_\\dagger>0$:\n\n(i) The interval $\\Big[\\sup_{|\\Delta|\\le L}\\tfrac{K_\\infty(\\Delta)}{L},\\ \\inf_{|\\Delta|\\ge\\Delta_\\dagger}\\tfrac{K_\\infty(\\Delta)}{|\\Delta|}\\Big]$ is empty.\n\n(ii) More generally, for any kernel $K:\\mathbb R\\to\\mathbb R$, define $K^{(\\beta)}(\\Delta):=K(\\Delta)-\\beta|\\Delta|$, and set $\\beta_-:=\\sup_{|\\Delta|\\ge\\Delta_\\dagger}\\tfrac{K(\\Delta)}{|\\Delta|}$ and $\\beta_+:=\\inf_{0<|\\Delta|\\le L}\\tfrac{K(\\Delta)}{|\\Delta|}$. Whenever $[\\beta_-,\\beta_+]$ is nonempty, every $\\beta\\in[\\beta_-,\\beta_+]$ satisfies $K^{(\\beta)}(\\Delta)\\ge0$ for $|\\Delta|\\le L$ and $K^{(\\beta)}(\\Delta)\\le0$ for $|\\Delta|\\ge\\Delta_\\dagger$ (in particular, if $K(0)\\ge0$ then $K^{(\\beta)}\\ge0$ on $[-L,L]$).",
  "Residue‑balanced bilinear cancellation. Let m_j,m_k∈ℕ be coprime and set M:=m_j m_k. Let m be uniformly distributed on ℤ/Mℤ (equivalently, the pair (m mod m_j, m mod m_k) is uniform on ℤ/m_jℤ×ℤ/m_kℤ). Put θ_j:=2π/m_j and θ_k:=2π/m_k. If (m_j,m_k)≠(1,1), then E_m[sin(θ_j m) sin(θ_k m)]=E_m[cos(θ_j m) cos(θ_k m)]=0. Consequently, for e_j(m):=(cos(θ_j m), sin(θ_j m))^⊤ and e_k(m):=(cos(θ_k m), sin(θ_k m))^⊤, one has E_m[e_j(m) e_k(m)^⊤]=0_{2×2}, so for any C∈ℝ^{2×2} the expected cross‑block bilinear loss L_C(m):=e_j(m)^⊤ C e_k(m) satisfies E_m[L_C(m)]=0 and ∇_C E_m[L_C(m)]=0_{2×2}.",
  "There exist 1≤α_1<α_2 and a finetuning schedule that samples residue classes uniformly modulo every m∈S_{α_1}∪S_{α_2} such that for some PI teacher at a scale α∈[α_1,α_2] the expected gradient of a quadratic feature‑matching loss on a coordinate in I_{S_{α_1}}∪I_{S_{α_2}} is nonzero.",
  "Token‑level residue dropout does not produce the claimed per‑residue (1−p) attenuation. Specifically, for any post‑critical RoPE block j≥c at scale α with modulus \\(\\hat\\lambda_j(\\alpha)\\in\\mathbb{N}\\), randomly dropping tokens in a uniformly chosen residue class modulo \\(\\hat\\lambda_j(\\alpha)\\) with probability p does not multiply that block’s expected relative‑position kernel by (1−p) on offsets congruent to the chosen class while leaving other offsets unchanged in expectation. In contrast, an offset‑level gate that multiplies entries with offsets in the chosen residue class by an independent Bernoulli(q) variable realizes the exact per‑residue (1−p) attenuation; compounded across independent residue classes the attenuations multiply, and restricting masking to post‑critical blocks leaves pre‑critical coordinates unbiased under residue‑balanced sampling.",
  "Weighted‑MSE optimal scaling. Fix α≥1 and a block with frequency θ_j>0 (equivalently, wavelength λ_j=2π/θ_j∈(0,∞)). For any nonnegative weight w with 0<∫_{ℝ}w(Δ)\\,dΔ<∞, define\n$$\nJ_j(s;w):=\\int_{\\mathbb R} w(\\Delta)\\,\\big\\| (\\cos(\\tfrac{\\theta_j\\Delta}{s}),\\sin(\\tfrac{\\theta_j\\Delta}{s}))-(\\cos(\\tfrac{\\theta_j\\Delta}{\\alpha}),\\sin(\\tfrac{\\theta_j\\Delta}{\\alpha}))\\big\\|^2\\,d\\Delta,\\qquad s\\in[1,\\alpha].\n$$\nThen $J_j(\\cdot;w)$ has the unique minimizer $s_j^{\\ast}(w)=\\alpha$. Moreover, if $w$ is uniform on $[-\\alpha L,\\alpha L]$ (with $L>0$), then\n$$\nL_{\\mathrm{eff}}(w):=\\sqrt{\\frac{\\int_{\\mathbb R} w(\\Delta)\\,\\Delta^2\\,d\\Delta}{\\int_{\\mathbb R} w(\\Delta)\\,d\\Delta}}=\\frac{\\alpha L}{\\sqrt{3}}.\n$$",
  "Layerwise geometric α-grid mimics the continuum at rate O(1/D). For D≥2 and α≥1, fix an index j with parameter θ_j∈ℝ. Define α_ℓ:=α^{(ℓ-1)/(D-1)} and K^{\\mathrm{layer}}_{D,j}(\\Delta):=\\tfrac1D\\sum_{\\ell=1}^D\\cos(\\Delta\\,\\theta_j/\\alpha_\\ell). Let K_\\infty(\\Delta):=\\int_0^1\\cos(\\Delta\\,\\theta_j/\\alpha^t)\\,dt and I_{\\alpha L}:=\\{\\Delta\\in\\\\mathbb{Z}:|\\Delta|\\le \\alpha L\\}. Then \\mathcal{E}_{\\infty}(K^{\\mathrm{layer}}_{D,j}-K_\\infty;I_{\\alpha L})=O(1/D), with the same O(1/D) scaling in average-squared error over I_{\\alpha L}.",
  "Rounded-PI teacher: sharp phase-error bounds and failure of the 1/2-constant for nearest-integer rounding. Fix α>0 and a wavelength λ_j>0 with w:=αλ_j≥1. Let N:=round(w)∈ℕ, define θ_j:=2π/λ_j, \\check θ_j:=2π/N, and δ^{(α)}_j:=\\bigl|\\tfrac{θ_j}{α}-\\check θ_j\\bigr|. Then: (i) The uniform nearest–integer bound |δ^{(α)}_j|≤\\tfrac{π}{α^2λ_j^2} (and hence sup_{|Δ|≤αL}|\\cos(Δθ_j/α)−\\cos(Δ\\check θ_j)|≤\\tfrac{πL}{αλ_j^2}) fails in general. (ii) Uniformly one has the sharp bounds |δ^{(α)}_j|≤\\tfrac{3π}{2α^2λ_j^2} and sup_{|Δ|≤αL}|\\cos(Δθ_j/α)−\\cos(Δ\\check θ_j)|≤\\tfrac{3πL}{2αλ_j^2}; the constant 3/2 is optimal. (iii) If nearest–integer rounding rounds upward (i.e., N≥w and |w−N|≤1/2), then |δ^{(α)}_j|≤\\tfrac{π}{α^2λ_j^2} and sup_{|Δ|≤αL}|\\cos(Δθ_j/α)−\\cos(Δ\\check θ_j)|≤\\tfrac{πL}{αλ_j^2}. (iv) Under pure ceiling rounding N:=\\lceil w\\rceil one has |δ^{(α)}_j|≤\\tfrac{2π}{α^2λ_j^2} and sup_{|Δ|≤αL}|\\cos(Δθ_j/α)−\\cos(Δ\\check θ_j)|≤\\tfrac{2πL}{αλ_j^2}; the 1/2-constant fails uniformly in this regime.",
  "Warp‑aware two‑regime MSE scaling. For a block j with wavelength $\\lambda_j=2\\pi/\\theta_j$ and target scale $\\alpha\\ge1$, minimizing the warp‑aware weighted alignment $J^{(g)}_j(s;w,\\mu)$ over $s\\in[1,\\alpha]$ yields the optimizer $$s^{\\star}_j(w,g,\\mu)=\\min\\Big\\{\\alpha,\\sqrt{\\tfrac{L_{\\mathrm{eff}}(g;w,\\mu)}{\\lambda_j}}\\Big\\}.$$ Consequently, any warp $g$ with $L_{\\mathrm{eff}}(g;w,\\mu)\\le L_{\\mathrm{eff}}(\\mathrm{id};w,\\mu)$ strengthens locality while the matching target $t\\mapsto\\sin(\\theta_j t/\\alpha)$ is unchanged, preserving the same two‑regime law.",
  "Head-wise phase dithering does not, in general, enforce exponential decay. Let per-head perturbations δ_{j,h} satisfy E[δ_{j,h}]=0 and Var(δ_{j,h})=σ_j^2. Then it is not necessarily true that (1/H)∑_{h=1}^H E[cos(Δ δ_{j,h})]=exp(−½σ_j^2Δ^2) for a fixed Δ. However, for |Δ|≤L one has (1/H)∑_{h=1}^H[1−E cos(Δ δ_{j,h})]≤½σ_j^2Δ^2=O(σ_j^2L^2). Moreover, if δ_{j,h}∼N(0,σ_j^2) for all h, then (1/H)∑_{h=1}^H E[cos(Δ δ_{j,h})]=exp(−½σ_j^2Δ^2); conversely, in the i.i.d. symmetric case, this equality for all Δ∈ℝ characterizes the Gaussian law.",
  "Geometric α-grid averaging across heads. Fix α≥1, θ∈ℝ, and L>0. For H≥2 define α_h:=α^{(h−1)/(H−1)} and, for Δ∈[−αL,αL], set K_H(Δ):=H^{-1}\n∑_{h=1}^H cos(Δθ/α_h). Define the continuum teacher T(Δ):=∫_0^1 cos(Δθ/α^t)dt (i.e., t∼Unif[0,1]). Then K_H→T uniformly on [−αL,αL] with discrete-to-continuum approximation error O(1/H). Moreover, if α>1, for every s∈[0,1] the single-scaling kernel A_s(Δ):=cos(Δθ/α^s) satisfies sup_{|Δ|≤αL}|K_H(Δ)−T(Δ)|<sup_{|Δ|≤αL}|A_s(Δ)−T(Δ)| for all sufficiently large H; when α=1, K_H≡T≡A_s for all s. Finally, for any probability measure ρ on [−αL,αL], the average-squared error ∫|K_H−T|^2 dρ is O(1/H^2) (hence O(1/H)).",
  "Counterexample to multi‑scale residue balancing. There exist scales α1=2<α2=3, a model instance with training window L=10 and a unique post‑critical block j=c with λ_c=10, and a finetuning schedule that uniformly samples residue classes modulo every m in S_{α1}∪S_{α2} (namely S_{α1}={20} and S_{α2}={30}), such that for a PI teacher at α=5/2 the expected gradient of a quadratic feature‑matching loss on a coordinate in I_{S_{α1}}∪I_{S_{α2}} is nonzero.",
  "LCM-sparse snapped spectrum across heads eliminates simultaneous phase collisions. For each post-critical block index j ≥ c, choose pairwise coprime positive integers N_{j,1},…,N_{j,H} and set θ_{j,h} := 2π/N_{j,h}. If two distinct positions m ≠ n collide in all heads (i.e., e^{iΔθ_{j,h}} = 1 for every h with Δ := n − m), then lcm(N_{j,1},…,N_{j,H}) divides Δ. Moreover, with coprime choices such as distinct primes one has lcm(N_{j,1},…,N_{j,H}) ≥ 2^H, so for H large enough there are no nonzero offsets |Δ| ≤ αL that collide simultaneously across all heads, while pre-critical coordinates (j < c) remain untouched by snapping.",
  "Dual‑scale antiphase sidelobe cancellation (corrected). Fix α≥1, j≥c, and a target distance Δ_{\\ast}∈[L,αL]. Put ω:=θ_j, t:=Δ_{\\ast}ω, and define the two‑head average K_{\\mathrm{pair}}(Δ):=\\tfrac12[\\cos(Δω/α)+\\cos(Δω/α')].\n\nUnconditional existence of α'∈[1,α] with K_{\\mathrm{pair}}(Δ_{\\ast})=0 and strict sidelobe suppression on I:=[Δ_{\\ast},3Δ_{\\ast}] is false in general. Exact cancellation at Δ_{\\ast} via the antiphase constraint \\tfrac{t}{2}(\\tfrac1{α'}-\\tfrac1α)=(2k+1)\\tfrac{π}{2} (k∈\\mathbb Z) holds if and only if t(1-1/α)≥π. Whenever this holds, there exists a feasible pair (α',k) with α'∈[1,α] such that:\n- K_{\\mathrm{pair}}(Δ_{\\ast})=0, and on I one has the factorization\n  K_{\\mathrm{pair}}(Δ)=(-1)^{k+1}\\sin\\tau\\,\\cos(A+b\\tau), with τ:=-(Δ-Δ_{\\ast})ω\\,δ∈[0,(2k+1)π], μ:=\\tfrac12(\\tfrac1α+\\tfrac1{α'}), δ:=\\tfrac12(\\tfrac1α-\\tfrac1{α'})≤0, A:=tμ=\\tfrac{t}{α}+\\tfrac{2k+1}{2}π, and b:=\\tfrac{μ}{|δ|}=1+\\tfrac{2t}{α(2k+1)π};\n- consequently, \\sup_{Δ∈I}|K_{\\mathrm{pair}}(Δ)|<1 unless (α',k) lies in the discrete resonance set \\mathcal R:=\\{(α',k):\\ ∃\\ m∈\\{0,1,\\dots,2k\\}\\text{ with }A+b(\\tfrac{π}{2}+mπ)∈π\\mathbb Z\\}, equivalently \\tfrac{t}{π\\alpha}\\cdot\\tfrac{2(m+k+1)}{2k+1}∈\\mathbb Z; in particular, if t/(πα) is irrational then the strict bound holds for every feasible (α',k).\nMoreover, for any feasible pair one has \\tfrac{2t}{α'}=\\tfrac{2t}{α}+2(2k+1)π>π, hence \\sup_{Δ∈I}|\\cos(Δω/α')|=1; if, in addition, I meets the π–lattice for the α–scale (equivalently \\sup_{Δ∈I}|\\cos(Δω/α)|=1), then for every feasible (α',k)∉\\mathcal R,\n\\sup_{Δ∈I}|K_{\\mathrm{pair}}(Δ)|<1=\\min\\{\\sup_{Δ∈I}|\\cos(Δω/α)|,\\ \\sup_{Δ∈I}|\\cos(Δω/α')|\\}.",
  "Union‑of‑layers spectral quadrature yields exponential teacher approximation governed by the total node count. Let nodes t_{ℓ,h}∈[0,1] and weights w_{ℓ,h} be assigned across layers ℓ=1,…,D and heads h=1,…,H_ℓ so that the multiset {(t_{ℓ,h},w_{ℓ,h})} coincides with the nodes and weights of some spectrally convergent Q‑node quadrature on [0,1], where Q=∑_{ℓ=1}^D H_ℓ. Then the globally averaged kernel K^{\\mathrm{union}}_{j}(Δ) satisfies, uniformly on I_{αL},\n\\[ \\mathcal{E}_{\\infty}\\bigl(K^{\\mathrm{union}}_{j} − K_\\infty; I_{αL}\\bigr)\\le C\\,\\rho^{−Q}. \\]\nThus distributing the Q quadrature nodes across layers and heads achieves the same exponential teacher‑approximation rate as using them in a single layer, governed solely by Q.",
  "CRT-coded residue dropout under an exactly-one rule realizes in expectation precisely those M-periodic attenuations whose values sum to M−1. Let m_1,\\dots,m_H be pairwise coprime, set M=\\prod_{h=1}^H m_h, and at each step choose a single residue Y\\in\\mathbb{Z}/M\\mathbb{Z} with probabilities (q_s)_{s\\in\\mathbb{Z}/M\\mathbb{Z}} and drop exactly that class. Then for all \\Delta, the expected multiplicative mask is \\mathbb{E}[X(\\Delta)]=1-q_{r(\\Delta)}. Moreover, an attenuation A:\\mathbb{Z}/M\\mathbb{Z}\\to[0,1] is realizable in expectation by this mechanism if and only if \\sum_{s\\in\\mathbb{Z}/M\\mathbb{Z}}A(s)=M-1, in which case one can take q_s=1-A(s). Via the Chinese remainder theorem, selecting a class s\\in\\mathbb{Z}/M\\mathbb{Z} can be implemented by coordinated residue gates modulo the m_h.",
  "Under only head-wise Gaussian phase micro-dithers applied on pre-critical blocks j<c with variances \\((\\sigma_j^2\\le \\kappa^2/L^2\\) (with \\(\\kappa\\ll1\\)), there is no universal constant \\(c>0\\) such that, for every OOD offset \\(\\Delta\\ne0\\) and every input \\(x\\), the per-coordinate bound \\[\\mathbb{E}_h\\big[\\,|\\tilde f(x,n)_i-\\tilde f(x,m)_i|^2\\,\\big]\\ \\ge\\ c\\,(\\theta_j\\sigma_j\\Delta)^2\\,\\|(Wx)_{\\mathrm{block }j}\\|^2\\] holds for each pre-critical coordinate \\(i\\).",
  "Deterministic de-biased integer snapping yields quadratic-in-α error. Let j be any index and let α,L>0 with a:=αλ_j≥1. Define N_j^-:=⌊a⌋, N_j^+:=⌈a⌉, θ_j^{±}:=2π/N_j^{±}, and set δ_±:=θ_j^{±}-2π/a. Let p_j:=δ_-/(δ_-−δ_+) (with the convention that p_j is arbitrary if δ_+=δ_-=0). Define K^{\\mathrm{2snap}}_j(Δ):=p_j\\cos(Δ\\,θ_j^+)+(1-p_j)\\cos(Δ\\,θ_j^-) and K^{(α)}_j(Δ):=\\cos\\big(Δ\\,2π/a\\big). Then there exists a universal constant C such that\n$$\\mathcal{E}_\\infty\\big(K^{\\mathrm{2snap}}_j-K^{(α)}_j;I_{αL}\\big):=\\sup_{|Δ|\\le αL}\\big|K^{\\mathrm{2snap}}_j(Δ)-K^{(α)}_j(Δ)\\big|\\ \\le\\ C\\,\\frac{L^2}{α^2\\lambda_j^4}.$$\nIn particular, this de-biasing improves the O\\!\\big(\\tfrac{L}{α\\lambda_j^2}\\big) worst-case bound of single-snap rounding to O\\!\\big(\\tfrac{L^2}{α^2\\lambda_j^4}\\big).",
  "Impossibility of targeted notch-and-flattening with three symmetric dithers. Let the phases be δ∈{−φ,0,φ} and let weights w_{−},w_0,w_{+}∈ℝ. For any fixed s>0 and any prescribed Δ_*, if\n\\[\\sum_{\\delta\\in\\{−\\phi,0,\\phi\\}} w_\\delta\\,\\cos\\bigl(\\Delta_*\\,\\tfrac{\\theta_j}{s}+\\delta\\bigr)=0,\\quad \\sum_{\\delta\\in\\{−\\phi,0,\\phi\\}} w_\\delta\\,\\sin\\bigl(\\Delta_*\\,\\tfrac{\\theta_j}{s}+\\delta\\bigr)=0,\\]\\nthen the head-average\n\\[K(\\Delta):=\\sum_{\\delta\\in\\{−\\phi,0,\\phi\\}} w_\\delta\\,\\cos\\bigl(\\Delta\\,\\tfrac{\\theta_j}{s}+\\delta\\bigr)\\]\\nvanishes identically for all Δ. Consequently, an exact targeted notch with zero slope at a prescribed Δ_* (without global cancellation) is impossible in this three-phase, fixed-scale setting; in particular, these constraints are incompatible with having in-window error O(\\phi^2) relative to the baseline cos(Δ\\,\\theta_j/s).",
  "Fix an index j, a scale \\alpha\\ge 1, and L>0. Let \\{t_h\\}\\_{h=1}^H\\subset[0,1] and positive weights \\{w_h\\}\\_{h=1}^H come from any positive interpolatory H-node quadrature on [0,1] that is exact for polynomials of degree at least H-1 (e.g., Gauss–Legendre or Clenshaw–Curtis), set s_h=\\alpha^{t_h}, and form K^{\\mathrm{quad}}_{w,H,j}. Then there exist constants C,\\,\\rho>1 depending only on (\\alpha,\\,\\theta_j L) such that uniformly on I_{\\alpha L}=[-\\alpha L,\\alpha L], \\ \\mathcal{E}_{\\infty}\\big(K^{\\mathrm{quad}}_{w,H,j}-K_\\infty; I_{\\alpha L}\\big)\\le C\\,\\rho^{-H}. Hence an H-head quadrature grid across \\alpha achieves exponentially small PI-mismatch.",
  "Multi‑lobe cancellation by solving for a small set of auxiliary scales. Fix α ≥ 1, a parameter θ_j ∈ ℝ, and q distinct target distances 0 < Δ_1 < ⋯ < Δ_q. There exist auxiliary scales s_1,…,s_q ∈ [1,α] and real weights a_0,…,a_q (with a_0>0 and baseline scale s_0:=α) such that the weighted kernel K(Δ):=∑_{r=0}^{q} a_r \\,\\cos(Δ\\,θ_j/s_r) satisfies K(Δ_ℓ)=0 for all ℓ=1,…,q. Moreover, for each compact set J that is a finite union of neighborhoods of {Δ_ℓ}, one can choose (s_r,a_r) so that sup_{Δ∈J}|K(Δ)| is strictly smaller than that of any single‑scale head H_s(Δ):=\\cos(Δ\\,θ_j/s) with s∈[1,α].",
  "q‑snap moment‑matched de‑biasing achieves O(α^{−q}) teacher mismatch. For any integer q≥2, any α≥1 and L≥0, and any block j with αλ_j≥1, there exist weights w^{(q)}_0,…,w^{(q)}_q with ∑_r w^{(q)}_r=1 and moment conditions\n\\[\\sum_{r=0}^{q} w^{(q)}_r\\,\\bigl( (N_j^{(r)})^{−1} − (α λ_j)^{−1} \\bigr)^k=0,\\quad k=1,\\dots,q−1,\\]\\nsuch that the q‑snap kernel K^{(q\\text{−}snap)}_j satisfies the uniform error bound on I_{αL}=[−αL,αL],\n\\[ \\mathcal{E}_{\\infty}\\bigl(K^{(q\\text{−}snap)}_j−K^{(α)}_j; I_{αL}\\bigr)\\le C_q\\, \\frac{L^{q}}{α^{q}\\,\\lambda_j^{2q}}, \\]\\nfor a constant C_q depending only on q."
]
