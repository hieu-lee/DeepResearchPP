(Robust convexity in expectation under bounded gradient noise.) Let f be convex and L-smooth, and consider stochastic GD x_{n+1}=x_n-\eta g(x_n,\xi_n) with \mathbb{E}[g(x,\xi)]=\nabla f(x) and \mathbb{E}\|g(x,\xi)-\nabla f(x)\|^2\le \sigma^2. For any \eta\in\big(0,\tfrac{2}{L}\big), there exists N=N(f,x_0,\eta,\sigma) such that the expected optimization curve \mathbb{E}[f(x_n)] is convex for all n\ge N. If f is \mu-strongly convex, one can take N\le C\,\kappa\,\log(1+\kappa\,\tfrac{f(x_0)-f_\star}{\eta\sigma^2}).